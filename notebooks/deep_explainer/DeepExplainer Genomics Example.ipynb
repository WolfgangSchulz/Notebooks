{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This runs DeepExplainer with the model trained on simualted genomic data from the DeepLIFT repo (https://github.com/kundajelab/deeplift/blob/master/examples/genomics/genomics_simulation.ipynb), using a dynamic reference (i.e. the reference varies depending on the input sequence; in this case, the reference is a collection of dinucleotide-shuffled versions of the input sequence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function, division\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pull in the relevant data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "! [[ ! -f sequences.simdata.gz ]] && wget https://raw.githubusercontent.com/AvantiShri/model_storage/db919b12f750e5844402153233249bb3d24e9e9a/deeplift/genomics/sequences.simdata.gz\n",
    "! [[ ! -f keras2_conv1d_record_5_model_PQzyq_modelJson.json ]] && wget https://raw.githubusercontent.com/AvantiShri/model_storage/b6e1d69/deeplift/genomics/keras2_conv1d_record_5_model_PQzyq_modelJson.json\n",
    "! [[ ! -f keras2_conv1d_record_5_model_PQzyq_modelWeights.h5 ]] && wget https://raw.githubusercontent.com/AvantiShri/model_storage/b6e1d69/deeplift/genomics/keras2_conv1d_record_5_model_PQzyq_modelWeights.h5\n",
    "! [[ ! -f test.txt.gz ]] && wget https://raw.githubusercontent.com/AvantiShri/model_storage/9aadb769735c60eb90f7d3d896632ac749a1bdd2/deeplift/genomics/test.txt.gz"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: simdna in /home/jan/shap/venv36tens2/lib/python3.6/site-packages (0.4.3.2)\r\n",
      "Requirement already satisfied: numpy>=1.9 in /home/jan/shap/venv36tens2/lib/python3.6/site-packages (from simdna) (1.18.5)\r\n",
      "Requirement already satisfied: matplotlib in /home/jan/shap/venv36tens2/lib/python3.6/site-packages (from simdna) (3.3.2)\r\n",
      "Requirement already satisfied: scipy in /home/jan/shap/venv36tens2/lib/python3.6/site-packages (from simdna) (1.5.4)\r\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /home/jan/shap/venv36tens2/lib/python3.6/site-packages (from matplotlib->simdna) (1.3.1)\r\n",
      "Requirement already satisfied: pillow>=6.2.0 in /home/jan/shap/venv36tens2/lib/python3.6/site-packages (from matplotlib->simdna) (8.0.1)\r\n",
      "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.3 in /home/jan/shap/venv36tens2/lib/python3.6/site-packages (from matplotlib->simdna) (2.4.7)\r\n",
      "Requirement already satisfied: python-dateutil>=2.1 in /home/jan/shap/venv36tens2/lib/python3.6/site-packages (from matplotlib->simdna) (2.8.1)\r\n",
      "Requirement already satisfied: certifi>=2020.06.20 in /home/jan/shap/venv36tens2/lib/python3.6/site-packages (from matplotlib->simdna) (2020.11.8)\r\n",
      "Requirement already satisfied: cycler>=0.10 in /home/jan/shap/venv36tens2/lib/python3.6/site-packages (from matplotlib->simdna) (0.10.0)\r\n",
      "Requirement already satisfied: six>=1.5 in /home/jan/shap/venv36tens2/lib/python3.6/site-packages (from python-dateutil>=2.1->matplotlib->simdna) (1.15.0)\r\n"
     ]
    }
   ],
   "source": [
    "! pip install simdna"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import simdna.synthetic as synthetic\n",
    "import gzip\n",
    "data_filename = \"sequences.simdata.gz\"\n",
    "\n",
    "#read in the data in the testing set\n",
    "test_ids_fh = gzip.open(\"test.txt.gz\",\"rb\")\n",
    "ids_to_load = [x.decode(\"utf-8\").rstrip(\"\\n\") for x in test_ids_fh]\n",
    "data = synthetic.read_simdata_file(data_filename, ids_to_load=ids_to_load)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "#this is set up for 1d convolutions where examples\n",
    "#have dimensions (len, num_channels)\n",
    "#the channel axis is the axis for one-hot encoding.\n",
    "def one_hot_encode_along_channel_axis(sequence):\n",
    "    to_return = np.zeros((len(sequence),4), dtype=np.int8)\n",
    "    seq_to_one_hot_fill_in_array(zeros_array=to_return,\n",
    "                                 sequence=sequence, one_hot_axis=1)\n",
    "    return to_return\n",
    "\n",
    "def seq_to_one_hot_fill_in_array(zeros_array, sequence, one_hot_axis):\n",
    "    assert one_hot_axis==0 or one_hot_axis==1\n",
    "    if one_hot_axis==0:\n",
    "        assert zeros_array.shape[1] == len(sequence)\n",
    "    elif one_hot_axis==1:\n",
    "        assert zeros_array.shape[0] == len(sequence)\n",
    "    #will mutate zeros_array\n",
    "    for (i,char) in enumerate(sequence):\n",
    "        if char==\"A\" or char==\"a\":\n",
    "            char_idx = 0\n",
    "        elif char==\"C\" or char==\"c\":\n",
    "            char_idx = 1\n",
    "        elif char==\"G\" or char==\"g\":\n",
    "            char_idx = 2\n",
    "        elif char==\"T\" or char==\"t\":\n",
    "            char_idx = 3\n",
    "        elif char==\"N\" or char==\"n\":\n",
    "            continue #leave that pos as all 0's\n",
    "        else:\n",
    "            raise RuntimeError(\"Unsupported character: \"+str(char))\n",
    "        if one_hot_axis==0:\n",
    "            zeros_array[char_idx,i] = 1\n",
    "        elif one_hot_axis==1:\n",
    "            zeros_array[i,char_idx] = 1\n",
    "            \n",
    "onehot_data = np.array([one_hot_encode_along_channel_axis(seq) for seq in data.sequences])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.models import model_from_json\n",
    "\n",
    "#load the keras model\n",
    "keras_model_weights = \"keras2_conv1d_record_5_model_PQzyq_modelWeights.h5\"\n",
    "keras_model_json = \"keras2_conv1d_record_5_model_PQzyq_modelJson.json\"\n",
    "\n",
    "keras_model = model_from_json(open(keras_model_json).read())\n",
    "keras_model.load_weights(keras_model_weights)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Install the deeplift package for the dinucleotide shuffling and visualzation code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: deeplift in /home/jan/shap/venv36tens2/lib/python3.6/site-packages (0.6.13.0)\r\n",
      "Requirement already satisfied: numpy>=1.9 in /home/jan/shap/venv36tens2/lib/python3.6/site-packages (from deeplift) (1.18.5)\r\n"
     ]
    }
   ],
   "source": [
    "!pip install deeplift"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compute importance scores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define the function that generates the reference, in this case by performing a dinucleotide shuffle of the given input sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'traverse_edges'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-8-91f78c859a4c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mdeeplift\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdinuc_shuffle\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdinuc_shuffle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraverse_edges\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshuffle_edges\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprepare_edges\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mcollections\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mCounter\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0monehot_dinuc_shuffle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0ms\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mImportError\u001b[0m: cannot import name 'traverse_edges'"
     ]
    }
   ],
   "source": [
    "from deeplift.dinuc_shuffle import dinuc_shuffle, traverse_edges, shuffle_edges, prepare_edges\n",
    "from collections import Counter\n",
    "\n",
    "def onehot_dinuc_shuffle(s): \n",
    "    s = np.squeeze(s)\n",
    "    argmax_vals = \"\".join([str(x) for x in np.argmax(s, axis=-1)])\n",
    "    shuffled_argmax_vals = [int(x) for x in traverse_edges(argmax_vals,                          \n",
    "                            shuffle_edges(prepare_edges(argmax_vals)))]    \n",
    "    to_return = np.zeros_like(s)    \n",
    "    to_return[list(range(len(s))), shuffled_argmax_vals] = 1    \n",
    "    return to_return\n",
    "\n",
    "shuffle_several_times = lambda s: np.array([onehot_dinuc_shuffle(s) for i in range(100)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run DeepExplainer with the dynamic reference function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from deeplift.visualization import viz_sequence\n",
    "import shap\n",
    "import shap.explainers.deep.deep_tf\n",
    "reload(shap.explainers.deep.deep_tf)\n",
    "reload(shap.explainers.deep)\n",
    "reload(shap.explainers)\n",
    "reload(shap)\n",
    "import numpy as np\n",
    "np.random.seed(1)\n",
    "import random\n",
    "\n",
    "seqs_to_explain = onehot_data[[0,3,9]] #these three are positive for task 0\n",
    "dinuc_shuff_explainer = shap.DeepExplainer((keras_model.input, keras_model.output[:,0]), shuffle_several_times)\n",
    "raw_shap_explanations = dinuc_shuff_explainer.shap_values(seqs_to_explain)\n",
    "\n",
    "#project the importance at each position onto the base that's actually present\n",
    "dinuc_shuff_explanations = np.sum(raw_shap_explanations,axis=-1)[:,:,None]*seqs_to_explain\n",
    "for dinuc_shuff_explanation in dinuc_shuff_explanations:\n",
    "    viz_sequence.plot_weights(dinuc_shuff_explanation, subticks_frequency=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
