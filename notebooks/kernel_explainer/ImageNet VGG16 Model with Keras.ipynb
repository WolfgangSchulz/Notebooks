{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ImageNet VGG16 Model with Keras\n",
    "\n",
    "This notebook demonstrates how to use the model agnostic Kernel SHAP algorithm to explain predictions from the VGG16 network in Keras."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pylab as pl\n",
    "import numpy as np\n",
    "import requests\n",
    "import shap\n",
    "from keras.applications.vgg16 import VGG16, preprocess_input\n",
    "from keras.preprocessing import image\n",
    "from skimage.segmentation import mark_boundaries\n",
    "from skimage.segmentation import slic\n",
    "\n",
    "# load model data\n",
    "r = requests.get('https://s3.amazonaws.com/deep-learning-models/image-models/imagenet_class_index.json')\n",
    "feature_names = r.json()\n",
    "model = VGG16()\n",
    "\n",
    "# load an image\n",
    "# file = \"data/apple_strawberry.jpg\"\n",
    "# file = \"data/apple.jpg\"\n",
    "# file = \"data/strawberry.jpg\"\n",
    "file = \"/home/jan/shap/notebooks/kernel_explainer/data/strawberry-with-grass.jpg\"\n",
    "\n",
    "img = image.load_img(file, target_size=(224, 224))\n",
    "img_orig = image.img_to_array(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "skimage.measure.label's indexing starts from 0. In future version it will start from 1. To disable this warning, explicitely set the `start_label` parameter to 1.\n"
     ]
    }
   ],
   "source": [
    "# segment the image so with don't have to explain every pixel\n",
    "segments_slic = slic(img, n_segments=50, compactness=30, sigma=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define a function that depends on a binary mask representing if an image region is hidden\n",
    "def mask_image(zs, segmentation, image, background=None):\n",
    "    if background is None:\n",
    "        background = image.mean((0,1))\n",
    "    out = np.zeros((zs.shape[0], image.shape[0], image.shape[1], image.shape[2]))\n",
    "    for i in range(zs.shape[0]):\n",
    "        out[i,:,:,:] = image\n",
    "        for j in range(zs.shape[1]):\n",
    "            if zs[i,j] == 0:\n",
    "                out[i][segmentation == j,:] = background\n",
    "    #%matplotlib inline\n",
    "    #fig, ax = plt.subplots(1, 1, figsize=(10, 10))\n",
    "    #outsqueezed = np.squeeze(out[0])\n",
    "    ##outsqueezed = outsqueezed[:, :, 1]\n",
    "    # https://scikit-image.org/docs/dev/auto_examples/segmentation/plot_segmentations.html\n",
    "    #ax.imshow(outsqueezed.astype('uint8'), cmap='Greys')\n",
    "    #ax.set_title(\"Masked image\")\n",
    "    #ax.set_axis_off()\n",
    "    #plt.tight_layout()\n",
    "    #plt.show()\n",
    "    return out\n",
    "def f(z):\n",
    "    return model.predict(preprocess_input(mask_image(z, segments_slic, img_orig, 255)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e0054e9bdcbf4c40ab108c65d36193bc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# use Kernel SHAP to explain the network's predictions\n",
    "explainer = shap.KernelExplainer(f, np.zeros((1,50)))\n",
    "shap_values = explainer.shap_values(np.ones((1,50)), nsamples=1000) # runs VGG16 1000 times"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the top predictions from the model\n",
    "preds = model.predict(preprocess_input(np.expand_dims(img_orig.copy(), axis=0)))\n",
    "top_preds = np.argsort(-preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make a color map\n",
    "from matplotlib.colors import LinearSegmentedColormap\n",
    "colors = []\n",
    "for l in np.linspace(1,0,100):\n",
    "    colors.append((245/255,39/255,87/255,l))\n",
    "for l in np.linspace(0,1,100):\n",
    "    colors.append((24/255,196/255,93/255,l))\n",
    "cm = LinearSegmentedColormap.from_list(\"shap\", colors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fill_segmentation(values, segmentation):\n",
    "    out = np.zeros(segmentation.shape)\n",
    "    for i in range(len(values)):\n",
    "        out[segmentation == i] = values[i]\n",
    "    return out\n",
    "\n",
    "# plot our explanations\n",
    "fig, axes = pl.subplots(nrows=1, ncols=4, figsize=(12,4))\n",
    "inds = top_preds[0]\n",
    "axes[0].imshow(mark_boundaries(img,segments_slic))\n",
    "axes[0].axis('off')\n",
    "max_val = np.max([np.max(np.abs(shap_values[i][:,:-1])) for i in range(len(shap_values))])\n",
    "for i in range(3):\n",
    "    m = fill_segmentation(shap_values[inds[i]][0], segments_slic)\n",
    "    axes[i+1].set_title(feature_names[str(inds[i])][1] + \" : \" + str(inds[i]))\n",
    "    axes[i+1].imshow(img.convert('LA'), alpha=0.15) # Gray scale\n",
    "    im = axes[i+1].imshow(m, cmap=cm, vmin=-max_val, vmax=max_val)\n",
    "    axes[i+1].axis('off')\n",
    "cb = fig.colorbar(im, ax=axes.ravel().tolist(), label=\"SHAP value\", orientation=\"horizontal\", aspect=60)\n",
    "cb.outline.set_visible(False)\n",
    "pl.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from skimage.segmentation import mark_boundaries\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "plt.imshow(mark_boundaries(img,segments_slic))\n",
    "plt.axis('off')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from skimage.segmentation import mark_boundaries\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "plt.imshow(mark_boundaries(img_orig,segments_slic))\n",
    "plt.axis('off')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}